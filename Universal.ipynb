{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.feature import hog\n",
    "from skimage import color, exposure\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import glob\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define all used color spaces\n",
    "def colorSpace(image, color):\n",
    "    \n",
    "    if color == 'rgb_r':\n",
    "        return image[:,:,0]\n",
    "    if color == 'rgb_g':\n",
    "        return image[:,:,1]\n",
    "    if color == 'rgb_b':\n",
    "        return image[:,:,2]\n",
    "    \n",
    "    if color == 'hls_h':\n",
    "        hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "        return hls[:,:,0]\n",
    "    if color == 'hls_l':\n",
    "        hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "        return hls[:,:,1]\n",
    "    if color == 'hls_s':\n",
    "        hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "        return hls[:,:,2]\n",
    "    \n",
    "    if color == 'yuv_y':\n",
    "        yuv = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "        return yuv[:,:,0]\n",
    "    if color == 'yuv_u':\n",
    "        yuv = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "        return yuv[:,:,1]\n",
    "    if color == 'yuv_v':\n",
    "        yuv = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "        return yuv[:,:,2]\n",
    "    \n",
    "    if color == 'lab_l':\n",
    "        lab = cv2.cvtColor(image, cv2.COLOR_RGB2Lab)\n",
    "        return lab[:,:,0]\n",
    "    if color == 'lab_a':\n",
    "        lab = cv2.cvtColor(image, cv2.COLOR_RGB2Lab)\n",
    "        return lab[:,:,1]\n",
    "    if color == 'lab_b':\n",
    "        lab = cv2.cvtColor(image, cv2.COLOR_RGB2Lab)\n",
    "        return lab[:,:,2]\n",
    "    \n",
    "    if color == 'gray':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalizeLayer(layer):\n",
    "    \n",
    "    # could be needed\n",
    "    #layer = np.array(layer, dtype=np.float32)\n",
    "    \n",
    "    x_min = (layer.min())\n",
    "    x_max = (layer.max())\n",
    "    \n",
    "    # ensure we have 0 bias!\n",
    "    a     = -0.5\n",
    "    b     =  0.5\n",
    "    \n",
    "    # type should be f32 from start!\n",
    "    return ( a + ( b - a ) * np.divide( ( layer - x_min ),  ( x_max - x_min ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hog fetures are allright, BUT then we need to normalize to 0 as keras would\n",
    "# prefer that. It is also convenient to do this PER layer, as in batch \n",
    "# normalization too. Should work with images too!\n",
    "def normalizeVolume(volume):\n",
    "    \n",
    "    # could be needed\n",
    "    #volume = np.array(volume, dtype=np.float32)\n",
    "    \n",
    "    # get dimensions, I asssume last dimension depicts layers/bins\n",
    "    bins = volume.shape[-1]\n",
    "    \n",
    "    # normalize and unbias each layer\n",
    "    for bin in range(bins):\n",
    "        layer = volume[:, :, bin]\n",
    "        volume[:, :, bin] = normalizeLayer(layer)\n",
    "        \n",
    "    return volumeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zeroOneRange(img):\n",
    "    \n",
    "    maxVal = img.max()\n",
    "    \n",
    "    if maxVal > 1.00001:\n",
    "        # promote to float32\n",
    "        img = np.asarray(img, dtype=np.float32)\n",
    "        # We assume range is 0 to 255\n",
    "        img = np.divide(img, 255.0)\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# it seems that hog works best on the Y channel, this makes sense according\n",
    "# o some object recognition papers as well\n",
    "# this replaces hog features\n",
    "def hogFeatures(img, \n",
    "                color='yuv_y',\n",
    "                orient=9, \n",
    "                pix_per_cell=8,\n",
    "                norm=False,\n",
    "                chkrange=True):\n",
    "    \n",
    "    if chkrange:\n",
    "        # check range, should fix type\n",
    "        img = zeroOneRange(img)\n",
    "    \n",
    "    # Apply image color space transform\n",
    "    img = colorSpace(img, color)\n",
    "    \n",
    "    # Obtain hog feaures of image, cells per block of 2x2 was\n",
    "    # selected as it is the simplest max pool layout, we will feed\n",
    "    # the features to a conv branch of a DNN, so we have to make a\n",
    "    \n",
    "    # few careful considerations (sizes, pooling, 'alignment'),\n",
    "    # normalization, color space, etc...\n",
    "    features = hog(img, \n",
    "                   orientations=orient, \n",
    "                   pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                   cells_per_block=(2, 2), \n",
    "                   transform_sqrt=True, \n",
    "                   visualise=False, \n",
    "                   feature_vector=False)\n",
    "    \n",
    "    # Now, the issue is that the blocks kind of repeat cells, so we might want\n",
    "    # to use a maxpool to 'equalize' the image, a way to do this would be to\n",
    "    # 'unroll' the cells in blocks, and apply a maxpool 2x2, however, we only\n",
    "    # want the pooling window to act over the 'intersections' of this reshape,\n",
    "    # it will need to be a custom reshape since we change the mem layout, and\n",
    "    # we want to add a 0 value exterior to allow this to be easily handled by \n",
    "    # the keras maxpool layer instead of doing it myself. This all reflects,\n",
    "    # quite expressively, the close relation between hog and the first layer of \n",
    "    # a conv. neural network, maybe ven more if we allow hog to consider higher\n",
    "    # order derivatives, and the maxpool application, and so on. \n",
    "    \n",
    "    # features right now must have shape\n",
    "    # (nx, ny, cx, cy, bin), and since cx=0,1, cy=0,1, we want a reshape as\n",
    "    # (nx*2, ny*2, 1, 1, bin), but since we want a border (like keras 'valid')\n",
    "    # (nx*2 + 2, ny*2 + 2, 1, 1, bin)\n",
    "    # since we change mem layout, we cannot use reshape, so lets do it!\n",
    "    nx   = features.shape[0]\n",
    "    ny   = features.shape[1]\n",
    "    cx   = 2 # assume constant non param\n",
    "    cy   = 2 # assume constant non param\n",
    "    bins = features.shape[4]\n",
    "    \n",
    "    # I have thought about other dimensions thant 2, but then I would need to\n",
    "    # 'interleave' the cells into bins, and it would be harder, moreso if the\n",
    "    # size is odd and so on... basically, looking for repetitions in the \n",
    "    # matrix and appending them one by one on the matrix and so on, possible\n",
    "    # but harder...\n",
    "    \n",
    "    nxp = 2 * nx + 2\n",
    "    nyp = 2 * ny + 2\n",
    "    \n",
    "    final_length = nxp * nyp * bins\n",
    "    linear = np.zeros((final_length), dtype=np.float32)\n",
    "    matrix = linear.reshape((nxp, nyp, bins))\n",
    "    \n",
    "    # populate the matrix with the 'flattened' hog features\n",
    "    for nxidx in range(nx):\n",
    "        for nyidy in range(ny):\n",
    "            # we are at nxidx, nyidy block\n",
    "            # this hast cx=2, cy=2 dimensions over cells\n",
    "            # and each cell has bins dim\n",
    "            # so get this subelement!\n",
    "            submatrix = features[nxidx, nyidy, :, :, :]\n",
    "            # prune spurious dims, maybe not needed though\n",
    "            submatrix = submatrix.reshape((2, 2, bins))\n",
    "            # assign to greater matrix, consider that we have a \n",
    "            # 1 element offset, also that cell dim is constant and two\n",
    "            matrix[(1 + 2 * nxidx):(3 + 2 * nxidx),\n",
    "                   (1 + 2 * nyidy):(3 + 2 * nyidy),\n",
    "                   :] = submatrix\n",
    "            \n",
    "    if norm:\n",
    "        # and normalize per layer\n",
    "        matrix = normalizeVolume(matrix)\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I will need to create a generator as well, as needed by keras as there are\n",
    "# 15k images, we also need to feed the color histograms as a vector, and also\n",
    "# the original image, though with much reduced resolutions, as we care mostly\n",
    "# about color actually, so maybe we wont even need the color histogram? \n",
    "# I mean, we already have the shape information, so it should be possible too\n",
    "# this replaces bin spatial\n",
    "def colorFeatures(image, \n",
    "                      norm=False,\n",
    "                      chkrange=True):\n",
    "    \n",
    "    if chkrange:\n",
    "        # check range\n",
    "        image = zeroOneRange(image)\n",
    "    \n",
    "    # First obtain the color maps/transforms of the image, on spaces\n",
    "    # recommended by udacity, these are rgb and hsv, we want them in 8x8\n",
    "    # pixel format, so get each layer, and resize it, better to use\n",
    "    # INTER_AREA for this though\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    # input form is rgb images, so this ought to work properly\n",
    "    rgb = image[:]\n",
    "    \n",
    "    # downsize our images, please note, size should mirror the one\n",
    "    # from hog features to avoid too many branches in network, even if we then\n",
    "    # prune information, I wonder if max is good in this case though, maybe...\n",
    "    # It could be ok to apply a first conv layer even here though, lets see\n",
    "    hsvm = np.zeros((16, 16, 3), dtype=np.float32)\n",
    "    rgbm = np.zeros((16, 16, 3), dtype=np.float32)\n",
    "    \n",
    "    hsvm[:,:,0] = cv2.resize( hsv[:,:,0], (16, 16), interpolation=cv2.INTER_AREA )  \n",
    "    hsvm[:,:,1] = cv2.resize( hsv[:,:,1], (16, 16), interpolation=cv2.INTER_AREA )  \n",
    "    hsvm[:,:,2] = cv2.resize( hsv[:,:,2], (16, 16), interpolation=cv2.INTER_AREA )  \n",
    "    \n",
    "    rgbm[:,:,0] = cv2.resize( rgb[:,:,0], (16, 16), interpolation=cv2.INTER_AREA )  \n",
    "    rgbm[:,:,1] = cv2.resize( rgb[:,:,1], (16, 16), interpolation=cv2.INTER_AREA )  \n",
    "    rgbm[:,:,2] = cv2.resize( rgb[:,:,2], (16, 16), interpolation=cv2.INTER_AREA ) \n",
    "    \n",
    "    if norm:\n",
    "        # normalize each layer as well\n",
    "        hsvm = normalizeVolume(hsvm)\n",
    "        rgbm = normalizeVolume(rgbm)\n",
    "    \n",
    "    # prepare are for join, we MUST use DSTACK for this    \n",
    "    return np.dstack((rgbm, hsvm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The other branch of the network will not deal with the image information locally, as hog\n",
    "# or bin spatial inherently are, but with the color histograms of the entire image to be\n",
    "# looked all at once, at this point we have (16*16*(9+6)) = 3840 points with local info, \n",
    "# histograms should give 32*3*2 (bins*channels*colorspaces) = 192 points, this seems...\n",
    "# ok...\n",
    "# please note that range is 0 to 1, as image range for pngs is 0 to 1\n",
    "def histFeatures( img,\n",
    "                  nbins=32,\n",
    "                  bins_range=(0,1),\n",
    "                  norm=False,\n",
    "                  chkrange=True):\n",
    "    \n",
    "    if chkrange:\n",
    "        # we could use hsv and rgb color spaces as well though, check range\n",
    "        img = zeroOneRange(img)\n",
    "    \n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    \n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    # And in HSV color space\n",
    "    channel4_hist = np.histogram(hsv[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel5_hist = np.histogram(hsv[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel6_hist = np.histogram(hsv[:,:,2], bins=nbins, range=bins_range)\n",
    "    \n",
    "    # We should narmalize them, per channel/layer\n",
    "    # Though, to be fair, these should be done at the batch level!\n",
    "    # or entire feature set\n",
    "    if norm:\n",
    "        channel1_hist[0] = normalizeLayer(channel1_hist[0])\n",
    "        channel2_hist[0] = normalizeLayer(channel2_hist[0])\n",
    "        channel3_hist[0] = normalizeLayer(channel3_hist[0])\n",
    "        channel4_hist[0] = normalizeLayer(channel4_hist[0])\n",
    "        channel5_hist[0] = normalizeLayer(channel5_hist[0])\n",
    "        channel6_hist[0] = normalizeLayer(channel6_hist[0])\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], \n",
    "                                    channel2_hist[0], \n",
    "                                    channel3_hist[0],\n",
    "                                    channel4_hist[0], \n",
    "                                    channel5_hist[0], \n",
    "                                    channel6_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the generator for keras? Yoy know what, a CNN is not really a good\n",
    "# fit for this though, lets try a simple SVM, so, obtain a generator, but of\n",
    "# the features only\n",
    "# Divide up into cars and notcars, maybe later I will break and adapt this to a\n",
    "# CNN or something, but I do not have that much time unfortunately, as I would\n",
    "# need to experiment a LOT!\n",
    "def separator(pattern='imgs/*.png'):\n",
    "    \n",
    "    images  = glob.glob(pattern)\n",
    "    cars    = []\n",
    "    notcars = []\n",
    "    \n",
    "    for image in images:\n",
    "        if 'image' in image or 'extra' in image:\n",
    "            notcars.append(image)\n",
    "        else:\n",
    "            cars.append(image)\n",
    "            \n",
    "    return cars, notcars\n",
    "\n",
    "def extractor(files):\n",
    "    \n",
    "    allfeatures = []\n",
    "        \n",
    "    for file in files:\n",
    "        image = mpimg.imread(file)\n",
    "        \n",
    "        hogf = hogFeatures(image)\n",
    "        clrf = colorFeatures(image)\n",
    "        hstf = histFeatures(image)\n",
    "        \n",
    "        features = np.concatenate((np.ndarray.flatten(hogf), \n",
    "                                   np.ndarray.flatten(clrf),\n",
    "                                   np.ndarray.flatten(hstf)))\n",
    "        \n",
    "        allfeatures.append(features)\n",
    "        \n",
    "    return allfeatures\n",
    "\n",
    "def generator(pattern='imgs/*.png'):\n",
    "    \n",
    "    cars, notcars = separator(pattern)\n",
    "            \n",
    "    car_features = extractor(cars)\n",
    "    notcar_features = extractor(notcars)\n",
    "        \n",
    "    # Create an array stack of feature vectors\n",
    "    X = np.vstack((car_features, notcar_features)).astype(np.float32)                        \n",
    "    # Fit a per-column scaler\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    # Apply the scaler to X\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "    # Define the labels vector\n",
    "    y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "    return scaled_X, y, X_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x,y,scaler = generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SVCwrapper(x, y):\n",
    "    \n",
    "    # Split up data into randomized training and test sets\n",
    "    rand_state = np.random.randint(0, 100)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, \n",
    "                                                        y, \n",
    "                                                        test_size=0.2, \n",
    "                                                        random_state=rand_state)\n",
    "\n",
    "    # Use a linear SVC \n",
    "    svc = LinearSVC()\n",
    "    # Check the training time for the SVC\n",
    "    t=time.time()\n",
    "    svc.fit(X_train, y_train)\n",
    "    t2 = time.time()\n",
    "    print(t2-t, 'Seconds to train SVC...')\n",
    "    # Check the score of the SVC\n",
    "    print('Train Accuracy of SVC = ', svc.score(X_train, y_train))\n",
    "    print('Test Accuracy of SVC = ', svc.score(X_test, y_test))\n",
    "    # Check the prediction time for a single sample\n",
    "    t=time.time()\n",
    "    prediction = svc.predict(X_test[0].reshape(1, -1))\n",
    "    t2 = time.time()\n",
    "    print(t2-t, 'Seconds to predict with SVC')\n",
    "    print(prediction)\n",
    "    \n",
    "    return svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 99.87! I will not beat that with a NN!\n",
    "# Just 4 examples were missclassed, ALL\n",
    "# within a very short distance from 0\n",
    "svc = SVCwrapper(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fitExplorer(x, y, svc):\n",
    "    \n",
    "    plt.plot(y, 'x')\n",
    "    plt.show()\n",
    "    \n",
    "    predictions = svc.predict(x)\n",
    "    distances   = svc.decision_function(x)\n",
    "    plt.plot(distances, '.')\n",
    "    plt.show()\n",
    "    \n",
    "    sortedf = (np.sort(distances))\n",
    "    inner   = sortedf[(sortedf >= -0.2) & (sortedf <= 0.2)]\n",
    "    plt.plot(inner, 'o')\n",
    "    plt.show()\n",
    "\n",
    "    problem_idx_prednoncar = distances[(predictions < 0.1) & (y > 0.9)]\n",
    "    plt.plot(problem_idx_prednoncar, 'o')\n",
    "    plt.show()\n",
    "\n",
    "    problem_idx_predcar = distances[(predictions > 0.9) & (y < 0.1)]\n",
    "    plt.plot(problem_idx_predcar, 'o')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fitExplorer(x, y, svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def thresholdedEvaluator(img,\n",
    "                         svc, \n",
    "                         scaler,\n",
    "                         threshold = 0.2):\n",
    "    # We want to apply a threshold for identification of cars, as shown in\n",
    "    # the explored data above, we really want to do this to predict a car, \n",
    "    # as dealing with hard negatives is hard\n",
    "    # 0.2 seems ok from data\n",
    "    img = cv2.resize(img, (64, 64), interpolation=cv2.INTER_AREA)\n",
    "    # just in case we have conflicts with png, jpg, mpimg, cv2, etc\n",
    "    img = zeroOneRange(img)\n",
    "    # apply feature extractor\n",
    "    hogf = hogFeatures(img)\n",
    "    clrf = colorFeatures(img)\n",
    "    hstf = histFeatures(img)\n",
    "    features = np.concatenate((np.ndarray.flatten(hogf), \n",
    "                               np.ndarray.flatten(clrf),\n",
    "                               np.ndarray.flatten(hstf)))\n",
    "    # we need to apply the scaler found for svc\n",
    "    scaled_x = scaler.transform(features.reshape((1,-1)))\n",
    "        \n",
    "    distance = svc.decision_function(scaled_x)\n",
    "    \n",
    "    evaluation = distance >= threshold\n",
    "    \n",
    "    return evaluation, distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global counter\n",
    "counter = 0\n",
    "\n",
    "def draw_boxes(img, \n",
    "               bboxes, \n",
    "               color=(0, 0, 255), \n",
    "               thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, tuple(bbox[0]), tuple(bbox[1]), color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy\n",
    "    \n",
    "# Adapt sliding window Udacity function to our needs\n",
    "# assume xy window is ALWAYS square\n",
    "def slide_window(img, \n",
    "                 window_list,\n",
    "                 x_start_stop=[None, None], \n",
    "                 y_center=None,\n",
    "                 xy_window=(64, 64), \n",
    "                 x_overlap=0.75):\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - x_overlap))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_windows = np.int(xspan/nx_pix_per_step) - 1\n",
    "    # Loop through finding x windows\n",
    "    for xs in range(nx_windows):\n",
    "        # Calculate window position\n",
    "        startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "        endx   = startx + xy_window[0]\n",
    "        # We will need to fix Y coordinates too, now there might be\n",
    "        # off by ones, but you know what, I do not care\n",
    "        starty = y_center - np.around(xy_window[1]/2)\n",
    "        endy   = y_center + np.around(xy_window[1]/2)\n",
    "        # Extract inner image with coordinates\n",
    "        window_image = img[starty:endy, startx:endx, :]\n",
    "        # extra args must come from outer context\n",
    "        value, dist = thresholdedEvaluator(window_image, svc, scaler)\n",
    "        # Append window position to list iff car is found\n",
    "        #plt.imshow(window_image)\n",
    "        #plt.show()\n",
    "        global counter\n",
    "        counter = counter + 1\n",
    "        if value:\n",
    "            window_list.append( ( (np.int(startx), np.int(starty)), (np.int(endx), np.int(endy)), dist ) )\n",
    "    # Return the list of windows\n",
    "    return len(window_list), window_list\n",
    "\n",
    "# apply sliding windows over all the image, with different\n",
    "# sizes and such depending on general position using helper func\n",
    "# by udacity, so it should work, maybe...\n",
    "def slideAll(img,\n",
    "             nlines = 20,\n",
    "             nvariations = 4,\n",
    "             pvariations = 0.25,\n",
    "             min_pixels = 40,\n",
    "             overlap = 0.75,\n",
    "             mode = 'linear'):\n",
    "    \n",
    "    global counter\n",
    "    counter = 0\n",
    "\n",
    "    # save all windows here\n",
    "    window_list = []\n",
    "    \n",
    "    # I will need to create sliding zones or something like that\n",
    "    # starx, endx, starty, endy\n",
    "    # parameters were carefully chosen, in such a way that a valid\n",
    "    # area is always generated, though box size might become to small\n",
    "    # so we chack for that\n",
    "    top_hportion = 0.7   #horizontal portion at top of vehicle lines\n",
    "    bot_hportion = 1     #horizontal portion at bottom of vehicles lines\n",
    "    top_vportion = 0     #vertical idem\n",
    "    bot_vportion = 0.333 #vertical idem\n",
    "    top_ydist    = 0.54  #proportion of image distance to top in image\n",
    "    bot_ydist    = 0.75  #proportion of image distance to top in image\n",
    "    \n",
    "    # we want to cover from the bottom to the top line, as in a scan by\n",
    "    # scan fashion, and on each, imagine a vertical box, and its variations\n",
    "    # so we want to create the x_lengths, do so\n",
    "    x_image = img.shape[1]\n",
    "    y_image = img.shape[0]\n",
    "    y_span  = np.round( y_image * (bot_ydist - top_ydist) )\n",
    "    y_bot   = np.round( y_image * bot_ydist )\n",
    "    \n",
    "    if mode == 'triangular':\n",
    "        # This really should be done in a way that upper sections are 'denser'\n",
    "        # so we can do this with a linear scaling! nice actually\n",
    "        maximal_steps = nlines * (nlines + 1) / 2\n",
    "        # and arrange as a triangular sum of sorts\n",
    "\n",
    "        # we will round on a case by case basis\n",
    "        y_fstep = np.true_divide( y_span, maximal_steps )\n",
    "        y_rtop  = y_bot - y_fstep * maximal_steps # just for consistency, wont use\n",
    "\n",
    "        # linear scaled steps\n",
    "        iter_steps = [ nlines - x for x in range(nlines + 1) ]\n",
    "        iter_sums  = [ sum(iter_steps[0:x]) for x in range(nlines + 1) ]\n",
    "        \n",
    "    if mode == 'linear':\n",
    "        maximal_steps = nlines\n",
    "        y_fstep = np.true_divide( y_span, maximal_steps )\n",
    "        y_rtop  = y_bot - y_fstep * maximal_steps # just for consistency, wont use\n",
    "        \n",
    "        iter_steps = [ 1 for x in range(nlines + 1) ]\n",
    "        iter_sums  = [ sum(iter_steps[0:x]) for x in range(nlines + 1) ]\n",
    "        \n",
    "    \n",
    "    # implement guard for 'dilution' if too many slices\n",
    "    y_center_old = 0\n",
    "    for idx in range(nlines):\n",
    "        y_center_new = y_bot - np.round(iter_sums[idx] * y_fstep)\n",
    "        if (abs(y_center_new - y_center_old) <= 1):\n",
    "            # we calculated the same line +-1px, no point going on\n",
    "            break;\n",
    "        y_center_old = y_center_new\n",
    "        \n",
    "        # calculate the spans in X\n",
    "        hportion  = iter_sums[idx] * (bot_hportion - top_hportion) / maximal_steps\n",
    "        h_idxspan = bot_hportion - hportion\n",
    "        x_start   = 0.5 * x_image - 0.5 * h_idxspan * x_image\n",
    "        x_end     = 0.5 * x_image + 0.5 * h_idxspan * x_image\n",
    "        \n",
    "        vportion  = iter_sums[idx] * (bot_vportion - top_vportion) / maximal_steps\n",
    "        v_idxspan = bot_vportion - vportion\n",
    "        y_span    = v_idxspan * y_image\n",
    "        \n",
    "        # round stuff\n",
    "        x_start = np.round(x_start)\n",
    "        x_end   = np.round(x_end)\n",
    "        y_span  = np.round(y_span)\n",
    "        \n",
    "        #print((x_start, x_end, y_span, y_center_new))\n",
    "        \n",
    "        if y_span < min_pixels:\n",
    "            #/ (1 - pvariations):\n",
    "            # windows will be too small, no point going on\n",
    "            break;\n",
    "            \n",
    "        if abs(x_start - x_end) < min_pixels/ (1 - pvariations):\n",
    "            #idem\n",
    "            break;\n",
    "            \n",
    "        #print((x_start, x_end))\n",
    "            \n",
    "        # However we will try with many variations over y_span, so\n",
    "        # also check those\n",
    "        if nvariations > 0:\n",
    "            varrange = range( nvariations, -nvariations - 1, -1 )\n",
    "            var_step = np.round( y_span * pvariations / nvariations )\n",
    "        else:\n",
    "            varrange = range(1)\n",
    "            var_step = np.round( y_span )\n",
    "            \n",
    "        for idy in varrange:\n",
    "            # maybe there could be checks here too?\n",
    "            local_yspan = y_span + idy * var_step\n",
    "            # somewhat ugly but I dont want to flatten\n",
    "            finds, window_list = slide_window(img, \n",
    "                                              window_list,\n",
    "                                              x_start_stop=[x_start, x_end], \n",
    "                                              y_center=y_center_new,\n",
    "                                              xy_window=(local_yspan, local_yspan), \n",
    "                                              x_overlap=overlap)\n",
    "                \n",
    "    return window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/test1.jpg')\n",
    "window_list = slideAll( img,\n",
    "                         nlines = 6,\n",
    "                         nvariations = 1,\n",
    "                         pvariations = 0.30,\n",
    "                         min_pixels = 64,\n",
    "                         overlap = 0.8 )\n",
    "\n",
    "window_img = draw_boxes(img, window_list, color=(0, 0, 255), thick=3)                    \n",
    "plt.imshow(window_img)\n",
    "plt.show()\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# adapted from https://github.com/quantombone/exemplarsvm/blob/54c07ec4faa96fb949991ebc512eaf7446e034f7/internal/esvm_nms.m\n",
    "# or http://www.computervisionblog.com/2011/08/blazing-fast-nmsm-from-exemplar-svm.html\n",
    "def esvm_nms(boxes, overlap):\n",
    "    \n",
    "    boxes = np.asarray(boxes)\n",
    "    \n",
    "    top = []\n",
    "    \n",
    "    if len(boxes) == 0:\n",
    "        return top\n",
    "    \n",
    "    # extract arrays of cornes\n",
    "    x1 = np.asarray([bbox[0][0] for bbox in boxes])\n",
    "    y1 = np.asarray([bbox[0][1] for bbox in boxes])\n",
    "    x2 = np.asarray([bbox[1][0] for bbox in boxes])\n",
    "    y2 = np.asarray([bbox[1][1] for bbox in boxes])\n",
    "    s  = [bbox[2][0] for bbox in boxes]\n",
    "    \n",
    "    area = ( x2 - x1 + 1 ) * ( y2 - y1 + 1 )\n",
    "    sIdx = np.argsort(s)\n",
    "\n",
    "    pick    = np.zeros_like(s)\n",
    "    counter = 0\n",
    "    \n",
    "    while (len(sIdx) > 0):\n",
    "        \n",
    "        last = len(sIdx) - 1\n",
    "        iidx = sIdx[last]  \n",
    "        pick[counter] = iidx\n",
    "        counter = counter + 1\n",
    "\n",
    "        xx1 = np.maximum(x1[iidx] * np.ones_like(last), x1[sIdx[0:(last)]])\n",
    "        yy1 = np.maximum(y1[iidx] * np.ones_like(last), y1[sIdx[0:(last)]])\n",
    "        xx2 = np.minimum(x2[iidx] * np.ones_like(last), x2[sIdx[0:(last)]])\n",
    "        yy2 = np.minimum(y2[iidx] * np.ones_like(last), y2[sIdx[0:(last)]])\n",
    "\n",
    "        w = np.maximum(np.zeros_like(last), xx2 - xx1 + 1 )\n",
    "        h = np.maximum(np.zeros_like(last), yy2 - yy1 + 1 )\n",
    "\n",
    "        o = np.divide( w * h, area[sIdx[0:(last)]] )\n",
    "        \n",
    "        prune_idx =  np.concatenate(( [last], np.nonzero(o > overlap)[0] ))\n",
    "        sIdx[prune_idx] = -1\n",
    "        sIdx = [x for x in sIdx if x > -1]\n",
    "        sIdx = np.asarray(sIdx)\n",
    "\n",
    "    pick = pick[0:(counter)];\n",
    "    top = boxes[(pick.astype(int))];\n",
    "    \n",
    "    return top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tops = esvm_nms(window_list, 0.5)\n",
    "window_img = draw_boxes(img, tops, color=(0, 0, 255), thick=3)                    \n",
    "plt.imshow(window_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def heatMap(img,\n",
    "            llist_windows,\n",
    "            frames):\n",
    "    \n",
    "    # select only the last frames\n",
    "    \n",
    "    # watch out for a deque\n",
    "    if type(llist_windows) == collections.deque:\n",
    "        llist_windows = list( llist_windows )\n",
    "        \n",
    "    last_windows = llist_windows[:-frames-1:-1]\n",
    "    \n",
    "    # create heat map over image, will norm later\n",
    "    imgmap = np.zeros_like(img[:,:,0], dtype=np.float32)\n",
    "    \n",
    "    # increment value of map if within box\n",
    "    for wlist in last_windows:\n",
    "        # why do i need this extra check?\n",
    "        if wlist is not None:\n",
    "            if len(wlist) > 0:\n",
    "                for window in wlist:\n",
    "                    x1 = (window[0][0])\n",
    "                    y1 = (window[0][1])\n",
    "                    x2 = (window[1][0])\n",
    "                    y2 = (window[1][1])\n",
    "                    s  = (window[2][0])\n",
    "                    # actually we only need an inner box, mmm\n",
    "                    imgmap[y1:y2,x1:x2] = imgmap[y1:y2,x1:x2] + np.log(s + 1)\n",
    "            \n",
    "    # normalize it\n",
    "    # no, this will raise false positives if not cars to the top\n",
    "    #imgmap = normalizeLayer(imgmap) + 0.5\n",
    "    #print(imgmap.max())\n",
    "    return imgmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "dq = collections.deque(maxlen=10)\n",
    "\n",
    "dq.append(window_list)\n",
    "dq.append(window_list)\n",
    "dq.append(window_list)\n",
    "\n",
    "hmap = heatMap(img,\n",
    "               dq,\n",
    "               5)\n",
    "\n",
    "plt.imshow(hmap)\n",
    "plt.show()\n",
    "print(hmap.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I recommend now thresholding for heatmap, use DBSCAN to id blobs\n",
    "# a long running heatmap is kind of a long term filter as well too\n",
    "# so no need for complicated filters, then expand box around found\n",
    "# point in heat map\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import data\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh\n",
    "from math import sqrt\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "def blobsFromHeatMap(hmap, \n",
    "                     threshold=3,\n",
    "                     draw=False):\n",
    "    \n",
    "    heatMap = np.copy(hmap)\n",
    "    \n",
    "    # resize for faster id gauss blob\n",
    "    heatMap = cv2.resize(heatMap, None, fx=0.25, fy=0.25, interpolation = cv2.INTER_AREA)\n",
    "    heatMap[heatMap < threshold] = 0\n",
    "    \n",
    "    # blur is very important for good selection\n",
    "    heatMap = cv2.blur(heatMap,(9, 9))\n",
    "    image = normalizeLayer(heatMap)\n",
    "    \n",
    "    # blob doh is too low performance\n",
    "    #blobs = blob_doh(image, max_sigma=200, threshold=.001)\n",
    "    \n",
    "    blobs = blob_dog(image, min_sigma=16, max_sigma=32, threshold=.1)\n",
    "    if blobs == None or len(blobs) == 0:\n",
    "         return None, None\n",
    "        \n",
    "    blobs[:, 2] = blobs[:, 2] * sqrt(2)\n",
    "        \n",
    "    if draw:\n",
    "        fig,ax = plt.subplots(1, 1)\n",
    "        ax.imshow(image)\n",
    "        for blob in blobs:\n",
    "            y, x, r = blob\n",
    "            c = plt.Circle((x, y), r, color='black', linewidth=2, fill=False)\n",
    "            ax.add_patch(c)\n",
    "        plt.show()\n",
    "        \n",
    "    # fix scale change\n",
    "    blobs[:, 0] = 4 * blobs[:, 0] \n",
    "    blobs[:, 1] = 4 * blobs[:, 1] \n",
    "    blobs[:, 2] = 4 * blobs[:, 2] \n",
    "    \n",
    "    # binarize image\n",
    "    heatMap[heatMap < 0.5] = 0\n",
    "    heatMap[heatMap > 0]   = 1\n",
    "\n",
    "    # Now we want to separate the two objects in image\n",
    "    # Generate the markers as local maxima of the distance to the background\n",
    "    distance = ndi.distance_transform_edt(heatMap)\n",
    "    local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((3, 3)),\n",
    "                                labels=heatMap)\n",
    "    markers = ndi.label(local_maxi)[0]\n",
    "    labels = watershed(-distance, markers, mask=heatMap)\n",
    "    \n",
    "    if draw:\n",
    "        fig, axes = plt.subplots(ncols=3, figsize=(8, 2.7), sharex=True, sharey=True, subplot_kw={'adjustable':'box-forced'})\n",
    "        ax0, ax1, ax2 = axes\n",
    "        ax0.imshow(heatMap, cmap=plt.cm.gray, interpolation='nearest')\n",
    "        ax0.set_title('Overlapping objects')\n",
    "        ax1.imshow(-distance, cmap=plt.cm.jet, interpolation='nearest')\n",
    "        ax1.set_title('Distances')\n",
    "        ax2.imshow(labels, cmap=plt.cm.spectral, interpolation='nearest')\n",
    "        ax2.set_title('Separated objects')\n",
    "        for ax in axes:\n",
    "            ax.axis('off')\n",
    "        fig.subplots_adjust(hspace=0.01, wspace=0.01, top=0.9, bottom=0, left=0,\n",
    "                            right=1)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    labels = cv2.resize(labels, None, fx=4, fy=4, interpolation = cv2.INTER_NEAREST)\n",
    "    \n",
    "    return blobs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Identify boxes in tops that are close to each blob by center\n",
    "# or use found blob areas to \n",
    "blobs, labels = blobsFromHeatMap(hmap, threshold=0, draw=True)\n",
    "print(blobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Finally, use the found tops, blobs and areas to draw bounding boxes\n",
    "# TODO vectorize this\n",
    "def getBoundingBoxes(blobs, tops, labels):\n",
    "    # each bounding box must be determined by blob center\n",
    "    # find boxes on tops that overlap center point\n",
    "    # find areas that overlap center point\n",
    "    yb = blobs[:, 0]\n",
    "    xb = blobs[:, 1]\n",
    "    rb = blobs[:, 2]\n",
    "    \n",
    "    # ok, I really dont care too much on efficiency right now\n",
    "    x1t = [ point[0] for point in tops[:,0] ]\n",
    "    x2t = [ point[0] for point in tops[:,1] ]\n",
    "    y1t = [ point[1] for point in tops[:,0] ]\n",
    "    y2t = [ point[1] for point in tops[:,1] ]\n",
    "    st  = [ value[0] for value in tops[:,2] ]\n",
    "    \n",
    "    x1t = np.asarray(x1t)\n",
    "    x2t = np.asarray(x2t)\n",
    "    y1t = np.asarray(y1t)\n",
    "    y2t = np.asarray(y2t)\n",
    "    st  = np.asarray(st)\n",
    "    \n",
    "    # center of box\n",
    "    cxt = 0.5 * (x1t + x2t)\n",
    "    cyt = 0.5 * (y1t + y2t)\n",
    "    \n",
    "    # assign blobs to tops\n",
    "    topblobs = -1 * np.ones((len(x1t)))\n",
    "    topdists = np.Infinity * np.ones((len(x1t)))\n",
    "    \n",
    "    for idxblob in range(len(xb)):\n",
    "        # calc distances to all blobs, center of this top box\n",
    "        blob_center_x = xb[idxblob]\n",
    "        blob_center_y = yb[idxblob]\n",
    "        # find mins, maybe use manhattan\n",
    "        disxy = np.sqrt( np.square(blob_center_x * np.ones_like(cxt) - cxt) + np.square(blob_center_y * np.ones_like(cyt) - cyt) )\n",
    "        # assign minima\n",
    "        for idxtop in range(len(disxy)):\n",
    "            if disxy[idxtop] < topdists[idxtop]:\n",
    "                topblobs[idxtop] = idxblob\n",
    "                topdists[idxtop] = disxy[idxtop]\n",
    "                \n",
    "    # check radius\n",
    "    for idxtop in range(len(topblobs)):\n",
    "        idxblob = topblobs[idxtop]\n",
    "        if topdists[idxtop] > 3 * rb[idxblob]:\n",
    "            topblobs[idxtop] = -1\n",
    "                \n",
    "    expanded_boxes = []\n",
    "    for idxblob in range(len(xb)):\n",
    "        blob_center_x = xb[idxblob]\n",
    "        blob_center_y = yb[idxblob]\n",
    "        blob_radius   = rb[idxblob] / 1.414\n",
    "        x1 = np.round( blob_center_x - blob_radius ).astype(int)\n",
    "        y1 = np.round( blob_center_y - blob_radius ).astype(int)\n",
    "        x2 = np.round( blob_center_x + blob_radius ).astype(int)\n",
    "        y2 = np.round( blob_center_y + blob_radius ).astype(int)\n",
    "        expanded_boxes.append( [[x1,y1],[x2,y2]] )\n",
    "            \n",
    "    for idx in range(len(topblobs)):\n",
    "        blob_idx_top = topblobs[idx]\n",
    "        if blob_idx_top > -1:\n",
    "            x1blob = expanded_boxes[blob_idx_top.astype(int)][0][0]\n",
    "            y1blob = expanded_boxes[blob_idx_top.astype(int)][0][1]\n",
    "            x2blob = expanded_boxes[blob_idx_top.astype(int)][1][0]\n",
    "            y2blob = expanded_boxes[blob_idx_top.astype(int)][1][1]\n",
    "            x1top  = x1t[idx]\n",
    "            y1top  = y1t[idx]\n",
    "            x2top  = x2t[idx]\n",
    "            y2top  = y2t[idx]\n",
    "            if x1top < x1blob:\n",
    "                expanded_boxes[blob_idx_top.astype(int)][0][0] = x1top\n",
    "            if y1top < y1blob:\n",
    "                expanded_boxes[blob_idx_top.astype(int)][0][1] = y1top\n",
    "            if x2top > x2blob:\n",
    "                expanded_boxes[blob_idx_top.astype(int)][1][0] = x2top\n",
    "            if y2top > y2blob:\n",
    "                expanded_boxes[blob_idx_top.astype(int)][1][1] = y2top\n",
    "            \n",
    "    #print(expanded_boxes)\n",
    "    # now find the areas for the blobs\n",
    "    #return expanded_boxes\n",
    "    \n",
    "    for idx in range(len(xb)):\n",
    "        \n",
    "        blob_center_x = xb[idx]\n",
    "        blob_center_y = yb[idx]\n",
    "        color = labels[blob_center_y][blob_center_x]\n",
    "        \n",
    "        blob_extent = np.zeros_like(labels)\n",
    "        blob_extent[labels == color] = 1\n",
    "        blob_points = np.nonzero(blob_extent)\n",
    "        \n",
    "        yvec = blob_points[0]\n",
    "        xvec = blob_points[1]\n",
    "        \n",
    "        xmin = np.min(xvec)\n",
    "        ymin = np.min(yvec)\n",
    "        xmax = np.max(xvec)\n",
    "        ymax = np.max(yvec)\n",
    "        \n",
    "        x1blob = expanded_boxes[blob_idx_top.astype(int)][0][0]\n",
    "        y1blob = expanded_boxes[blob_idx_top.astype(int)][0][1]\n",
    "        x2blob = expanded_boxes[blob_idx_top.astype(int)][1][0]\n",
    "        y2blob = expanded_boxes[blob_idx_top.astype(int)][1][1]\n",
    "        \n",
    "        if xmin < x1blob:\n",
    "            expanded_boxes[idx][0][0] = xmin\n",
    "        if ymin < y1blob:\n",
    "            expanded_boxes[idx][0][1] = ymin\n",
    "        if xmax > x2blob:\n",
    "            expanded_boxes[idx][1][0] = xmax\n",
    "        if ymax > y2blob:\n",
    "            expanded_boxes[idx][1][1] = ymax\n",
    "            \n",
    "    return expanded_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expanded = getBoundingBoxes(blobs, tops, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "window_img = draw_boxes(img, expanded, color=(0, 0, 255), thick=3)                    \n",
    "plt.imshow(window_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define our pipeline in here as well\n",
    "# classifier must have been define at outer context\n",
    "import collections\n",
    "\n",
    "global windowlistall\n",
    "windowlistall = collections.deque(maxlen=10)\n",
    "\n",
    "def imposeBoxes(image, draw = False):\n",
    "    \n",
    "    img = image\n",
    "    \n",
    "    window_list = slideAll( img,\n",
    "                             nlines = 8,\n",
    "                             nvariations = 2,\n",
    "                             pvariations = 0.40,\n",
    "                             min_pixels = 64,\n",
    "                             overlap = 0.8 )\n",
    "    \n",
    "    global windowlistall\n",
    "    windowlistall.append(window_list)\n",
    "\n",
    "    tops = esvm_nms(window_list, 0.5)\n",
    "    hmap = heatMap(img,\n",
    "                   windowlistall,\n",
    "                   10)\n",
    "    \n",
    "    if draw:\n",
    "        plt.imshow(hmap)\n",
    "        plt.show()\n",
    "\n",
    "    # id the blobs in here\n",
    "    blobs, labels = blobsFromHeatMap(hmap, threshold=20)\n",
    "    \n",
    "    if blobs is not None and len(blobs) > 0:\n",
    "\n",
    "        expanded = getBoundingBoxes(blobs, tops, labels)\n",
    "        window_img = draw_boxes(img, expanded, color=(0, 0, 255), thick=3) \n",
    "        if draw:\n",
    "            plt.imshow(window_img)\n",
    "            plt.show()\n",
    "        return window_img\n",
    "\n",
    "    else: \n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "#reinit qeue\n",
    "global windowlistall\n",
    "windowlistall = collections.deque(maxlen=10)\n",
    "\n",
    "m_output = 'output2.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "m_clip = clip1.fl_image(imposeBoxes) #NOTE: this function expects color images!!\n",
    "%time m_clip.write_videofile(m_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
